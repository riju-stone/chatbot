{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "interpreter": {
      "hash": "367a22c48e1536de14b506075fd69e0d92bf674c877f2d865483f55089c9211f"
    },
    "colab": {
      "name": "chatbot_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot V2 - Using Tensorflow & Keras"
      ],
      "metadata": {
        "id": "0faVM9oT73cE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "lQ1sa6vA73cE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import sys, os, re\r\n",
        "import random, string, time\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from tensorflow.keras.layers import add\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n",
        "from nltk.translate.bleu_score import corpus_bleu\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, GRU, TimeDistributed\r\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Bidirectional, Concatenate, Lambda\r\n",
        "\r\n",
        "test = False\r\n",
        "if test:\r\n",
        "    GRU_units = 10\r\n",
        "    batch_size = 4\r\n",
        "    emb_dim = 10\r\n",
        "else:\r\n",
        "    GRU_units = 256\r\n",
        "    batch_size = 32\r\n",
        "    emb_dim = 50\r\n",
        "\r\n",
        "init_lr = 0.0005"
      ],
      "outputs": [],
      "metadata": {
        "id": "Mm7wkxlX73cF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "def progressBar(value, endvalue, bar_length=20, job='Job'):\r\n",
        "\r\n",
        "    percent = float(value) / endvalue\r\n",
        "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\r\n",
        "    spaces = ' ' * (bar_length - len(arrow))\r\n",
        "\r\n",
        "    sys.stdout.write(\"\\r{0} Completion: [{1}] {2}%\".format(job,arrow + spaces, int(round(percent * 100))))\r\n",
        "    sys.stdout.flush()\r\n",
        "    \r\n",
        "def print_tensor(t):\r\n",
        "    print(K.get_value(t))\r\n",
        "    \r\n",
        "def to_tensor(t):\r\n",
        "    return tf.convert_to_tensor(t)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PA_W024U73cH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the Data"
      ],
      "metadata": {
        "id": "RJGhCWGp73cH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\r\n",
        "\r\n",
        "conversations = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\r\n",
        "\r\n",
        "# Mapping each line's id with its text\r\n",
        "id2line = {}\r\n",
        "for line in lines:\r\n",
        "    _line = line.split(' +++$+++ ')\r\n",
        "    if len(_line) == 5:\r\n",
        "        id2line[_line[0]] = _line[4]\r\n",
        "\r\n",
        "# List of all Conversation's Line's ids\r\n",
        "convs = []\r\n",
        "for line in conversations[:-1]:\r\n",
        "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\r\n",
        "    convs.append(_line.split(','))\r\n",
        "\r\n",
        "# Sort into Questions and Answers\r\n",
        "pairs = []\r\n",
        "for conv in convs:\r\n",
        "    for i in range(len(conv)-1):\r\n",
        "        pairs.append([id2line[conv[i]], id2line[conv[i+1]]])\r\n",
        "\r\n",
        "\r\n",
        "limit = 0\r\n",
        "for i in range(limit, limit+10):\r\n",
        "    print(pairs[i][0])\r\n",
        "    print(pairs[i][1])\r\n",
        "    print()\r\n",
        "    print()\r\n",
        "\r\n",
        "len(pairs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
            "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
            "\n",
            "\n",
            "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
            "Not the hacking and gagging and spitting part.  Please.\n",
            "\n",
            "\n",
            "Not the hacking and gagging and spitting part.  Please.\n",
            "Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
            "\n",
            "\n",
            "You're asking me out.  That's so cute. What's your name again?\n",
            "Forget it.\n",
            "\n",
            "\n",
            "No, no, it's my fault -- we didn't have a proper introduction ---\n",
            "Cameron.\n",
            "\n",
            "\n",
            "Cameron.\n",
            "The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
            "\n",
            "\n",
            "The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
            "Seems like she could get a date easy enough...\n",
            "\n",
            "\n",
            "Why?\n",
            "Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n",
            "\n",
            "\n",
            "Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n",
            "That's a shame.\n",
            "\n",
            "\n",
            "Gosh, if only we could find Kat a boyfriend...\n",
            "Let me see what I can do.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5_YMWCV73cH",
        "outputId": "e35d8a97-0283-4e93-c47a-762ccf1836af"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# replacing colloquial abbreviations and lower casing all the words\r\n",
        "\r\n",
        "def replace_phrase(pairs):\r\n",
        "    p = pairs.copy()\r\n",
        "\r\n",
        "    for i in p:\r\n",
        "        for j in range(0,2):\r\n",
        "            i[j] = i[j].lower()\r\n",
        "            i[j] = re.sub(r\"there's\", \"there is\", i[j])\r\n",
        "            i[j] = re.sub(r\"i'm\", \"i am\", i[j])\r\n",
        "            i[j] = re.sub(r\"he's\", \"he is\", i[j])\r\n",
        "            i[j] = re.sub(r\"she's\", \"she is\", i[j])\r\n",
        "            i[j] = re.sub(r\"it's\", \"it is\", i[j])\r\n",
        "            i[j] = re.sub(r\"that's\", \"that is\", i[j])\r\n",
        "            i[j] = re.sub(r\"what's\", \"that is\", i[j])\r\n",
        "            i[j] = re.sub(r\"where's\", \"where is\", i[j])\r\n",
        "            i[j] = re.sub(r\"how's\", \"how is\", i[j])\r\n",
        "            i[j] = re.sub(r\"\\'ll\", \" will\", i[j])\r\n",
        "            i[j] = re.sub(r\"\\'ve\", \" have\", i[j])\r\n",
        "            i[j] = re.sub(r\"\\'re\", \" are\", i[j])\r\n",
        "            i[j] = re.sub(r\"\\'d\", \" would\", i[j])\r\n",
        "            i[j] = re.sub(r\"\\'re\", \" are\", i[j])\r\n",
        "            i[j] = re.sub(r\"won't\", \"will not\", i[j])\r\n",
        "            i[j] = re.sub(r\"can't\", \"cannot\", i[j])\r\n",
        "            i[j] = re.sub(r\"n't\", \" not\", i[j])\r\n",
        "            i[j] = re.sub(r\"n'\", \"ng\", i[j])\r\n",
        "            i[j] = re.sub(r\"'bout\", \"about\", i[j])\r\n",
        "            i[j] = re.sub(r\"'til\", \"until\", i[j])\r\n",
        "            i[j] = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", i[j])\r\n",
        "            i[j] = i[j].strip()\r\n",
        "\r\n",
        "    return p\r\n",
        "\r\n",
        "replaced_pairs = replace_phrase(pairs)\r\n",
        "replaced_pairs[:10]\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['can we make this quick  roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad  again',\n",
              "  'well i thought we would start with pronunciation if that is okay with you'],\n",
              " ['well i thought we would start with pronunciation if that is okay with you',\n",
              "  'not the hacking and gagging and spitting part  please'],\n",
              " ['not the hacking and gagging and spitting part  please',\n",
              "  'okay then how about we try out some french cuisine  saturday  night'],\n",
              " ['you are asking me out  that is so cute that is your name again',\n",
              "  'forget it'],\n",
              " ['no no it is my fault  we did not have a proper introduction', 'cameron'],\n",
              " ['cameron',\n",
              "  'the thing is cameron  i am at the mercy of a particularly hideous breed of loser  my sister  i cannot date until she does'],\n",
              " ['the thing is cameron  i am at the mercy of a particularly hideous breed of loser  my sister  i cannot date until she does',\n",
              "  'seems like she could get a date easy enough'],\n",
              " ['why',\n",
              "  'unsolved mystery  she used to be really popular when she started high school then it was just like she got sick of it or something'],\n",
              " ['unsolved mystery  she used to be really popular when she started high school then it was just like she got sick of it or something',\n",
              "  'that is a shame'],\n",
              " ['gosh if only we could find kat a boyfriend', 'let me see what i can do']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mizZf1bu73cI",
        "outputId": "4a7fdee8-91ce-42d9-e5ce-d712bf8185ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "def clean_data(pairs):\r\n",
        "    p = pairs.copy()\r\n",
        "\r\n",
        "    # translation table for data manupulation\r\n",
        "    table = str.maketrans('', '', string.punctuation)\r\n",
        "\r\n",
        "    for i in p:\r\n",
        "        # tokenize\r\n",
        "        i[0], i[1] = i[0].split(), i[1].split()\r\n",
        "        # remove punctuation from each token\r\n",
        "        i[0], i[1] = [w.translate(table) for w in i[0]], [w.translate(table) for w in i[1]]\r\n",
        "         # remove tokens with numbers in them\r\n",
        "        i[0], i[1] = [word for word in i[0] if word.isalpha()], [word for word in i[1] if word.isalpha()]\r\n",
        "         # store as string\r\n",
        "        i[0], i[1] =  ' '.join(i[0]), ' '.join(i[1])\r\n",
        "\r\n",
        "    return p\r\n",
        "\r\n",
        "clean_pairs = clean_data(replaced_pairs)\r\n",
        "clean_pairs[:10]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['can we make this quick roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad again',\n",
              "  'well i thought we would start with pronunciation if that is okay with you'],\n",
              " ['well i thought we would start with pronunciation if that is okay with you',\n",
              "  'not the hacking and gagging and spitting part please'],\n",
              " ['not the hacking and gagging and spitting part please',\n",
              "  'okay then how about we try out some french cuisine saturday night'],\n",
              " ['you are asking me out that is so cute that is your name again',\n",
              "  'forget it'],\n",
              " ['no no it is my fault we did not have a proper introduction', 'cameron'],\n",
              " ['cameron',\n",
              "  'the thing is cameron i am at the mercy of a particularly hideous breed of loser my sister i cannot date until she does'],\n",
              " ['the thing is cameron i am at the mercy of a particularly hideous breed of loser my sister i cannot date until she does',\n",
              "  'seems like she could get a date easy enough'],\n",
              " ['why',\n",
              "  'unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something'],\n",
              " ['unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something',\n",
              "  'that is a shame'],\n",
              " ['gosh if only we could find kat a boyfriend', 'let me see what i can do']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XNngjlg73cJ",
        "outputId": "a6920c72-25e6-4007-c5f4-7689254ea82d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# adding starting and ending token for reference to each token\r\n",
        "\r\n",
        "start_token = '<strartseq>'\r\n",
        "end_token = '<endseq>'\r\n",
        "\r\n",
        "def add_start_end_tokens(pairs):\r\n",
        "    p = pairs.copy()\r\n",
        "    for i in p:\r\n",
        "        i[0] = start_token + ' ' + i[0] + ' ' + end_token\r\n",
        "        i[1] = start_token + ' ' + i[1] + ' ' + end_token\r\n",
        "    \r\n",
        "    return p\r\n",
        "\r\n",
        "tokenized_pairs = add_start_end_tokens(clean_pairs)\r\n",
        "tokenized_pairs[:10]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<strartseq> can we make this quick roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad again <endseq>',\n",
              "  '<strartseq> well i thought we would start with pronunciation if that is okay with you <endseq>'],\n",
              " ['<strartseq> well i thought we would start with pronunciation if that is okay with you <endseq>',\n",
              "  '<strartseq> not the hacking and gagging and spitting part please <endseq>'],\n",
              " ['<strartseq> not the hacking and gagging and spitting part please <endseq>',\n",
              "  '<strartseq> okay then how about we try out some french cuisine saturday night <endseq>'],\n",
              " ['<strartseq> you are asking me out that is so cute that is your name again <endseq>',\n",
              "  '<strartseq> forget it <endseq>'],\n",
              " ['<strartseq> no no it is my fault we did not have a proper introduction <endseq>',\n",
              "  '<strartseq> cameron <endseq>'],\n",
              " ['<strartseq> cameron <endseq>',\n",
              "  '<strartseq> the thing is cameron i am at the mercy of a particularly hideous breed of loser my sister i cannot date until she does <endseq>'],\n",
              " ['<strartseq> the thing is cameron i am at the mercy of a particularly hideous breed of loser my sister i cannot date until she does <endseq>',\n",
              "  '<strartseq> seems like she could get a date easy enough <endseq>'],\n",
              " ['<strartseq> why <endseq>',\n",
              "  '<strartseq> unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something <endseq>'],\n",
              " ['<strartseq> unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something <endseq>',\n",
              "  '<strartseq> that is a shame <endseq>'],\n",
              " ['<strartseq> gosh if only we could find kat a boyfriend <endseq>',\n",
              "  '<strartseq> let me see what i can do <endseq>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0WUfUNr73cJ",
        "outputId": "c20d9231-cb69-45cd-bf65-9d94b6731bee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# Calculating the max length of questions and answers that\n",
        "# most of the data can be placed in\n",
        "\n",
        "def max_length(pairs, percent):\n",
        "    answers = []\n",
        "    questions = []\n",
        "    for i in pairs:\n",
        "        questions.append(i[0])\n",
        "        answers.append(i[1])\n",
        "\n",
        "    length_questions = list(len(d.split()) for d in questions)\n",
        "    length_answers = list(len(d.split()) for d in answers)\n",
        "\n",
        "    print('percentile {} of len of questions: {}'.format(percent, np.percentile(length_questions, percent)))\n",
        "    print('longest question: ', max(length_questions))\n",
        "    print()\n",
        "\n",
        "    print('percentile {} of len of answers: {}'.format(percent, np.percentile(length_answers, percent)))\n",
        "    print('longest answers: ', max(length_answers))\n",
        "    print()\n",
        "\n",
        "    return int(np.percentile(length_questions, percent)), int(np.percentile(length_answers, percent))\n",
        "max_len_ques, max_len_ans = max_length(tokenized_pairs, 90)\n",
        "\n",
        "print('Max Len of questions for training: ', max_len_ques)\n",
        "print('Max Len of answers for training: ', max_len_ans)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percentile 90 of len of questions: 25.0\n",
            "longest question:  321\n",
            "\n",
            "percentile 90 of len of answers: 26.0\n",
            "longest answers:  557\n",
            "\n",
            "Max Len of questions for training:  25\n",
            "Max Len of answers for training:  26\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHePBzOo73cK",
        "outputId": "161a0747-3e47-45e0-fdda-604a8aaef57a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# Removing texts which are shorter than 2 words and longer than max length calculated\n",
        "\n",
        "min_len = 2\n",
        "\n",
        "def set_length(tokenized_pairs):\n",
        "    pairs_final = []\n",
        "    for p in tokenized_pairs:\n",
        "        if (len(p[0].split()) >= min_len and len(p[1].split()) >= min_len and len(p[0].split())<=max_len_ques and len(p[1].split())<=max_len_ans):\n",
        "            pairs_final.append(p)\n",
        "\n",
        "    return pairs_final\n",
        "\n",
        "pairs_final = set_length(tokenized_pairs)\n",
        "len(pairs_final)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180729"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG-DGRaF73cL",
        "outputId": "c9f25f37-b937-46f4-fc61-9c82d2850dc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the vocabulary"
      ],
      "metadata": {
        "id": "_9AMcYLo73cL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# creating a vocabulary of words that occur more than a\n",
        "# certain threshold\n",
        "\n",
        "def creating_reoccuring_vocab(pairs, word_count_threshold = 5):\n",
        "    p = pairs.copy()\n",
        "\n",
        "    # creating a list of all captions\n",
        "    all_captions = []\n",
        "    for i in p:\n",
        "        for j in i:\n",
        "            all_captions.append(j)\n",
        " \n",
        "    # only considering the words which occur at least 10 times in the corpus\n",
        "    word_counts = {}\n",
        "    nsents = 0\n",
        "    for sent in all_captions:\n",
        "        nsents += 1\n",
        "        for w in sent.split(' '):\n",
        "            word_counts[w] = word_counts.get(w, 0) + 1\n",
        "\n",
        "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
        "    vocab = list(set(vocab))\n",
        "    print('Vocab Size: ', len(vocab))\n",
        "    return vocab\n",
        "\n",
        "short_vocab = creating_reoccuring_vocab(pairs_final, word_count_threshold=4)\n",
        "\n",
        "# removing all one letter words except a and i\n",
        "for v in short_vocab:\n",
        "    if len(v) == 1 and v != 'a' and v != 'i':\n",
        "        short_vocab.remove(v)\n",
        "\n",
        "short_vocab = sorted(short_vocab)[1:]\n",
        "short_vocab"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size:  18619\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<endseq>',\n",
              " '<strartseq>',\n",
              " 'a',\n",
              " 'aa',\n",
              " 'aaaah',\n",
              " 'aaaahhhh',\n",
              " 'aaah',\n",
              " 'aah',\n",
              " 'aand',\n",
              " 'aannnnaahhnn',\n",
              " 'aaron',\n",
              " 'ab',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abba',\n",
              " 'abbe',\n",
              " 'abbott',\n",
              " 'abby',\n",
              " 'abc',\n",
              " 'abducted',\n",
              " 'abduction',\n",
              " 'abe',\n",
              " 'abetting',\n",
              " 'abhor',\n",
              " 'abide',\n",
              " 'abilities',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'abnormal',\n",
              " 'aboard',\n",
              " 'abomination',\n",
              " 'abort',\n",
              " 'abortion',\n",
              " 'about',\n",
              " 'above',\n",
              " 'abraham',\n",
              " 'abrams',\n",
              " 'abroad',\n",
              " 'abs',\n",
              " 'absence',\n",
              " 'absent',\n",
              " 'absenteeism',\n",
              " 'absolute',\n",
              " 'absolutely',\n",
              " 'absorb',\n",
              " 'abstract',\n",
              " 'absurd',\n",
              " 'absurde',\n",
              " 'abuse',\n",
              " 'abusive',\n",
              " 'academic',\n",
              " 'academy',\n",
              " 'accelerate',\n",
              " 'accelerated',\n",
              " 'accelerating',\n",
              " 'accent',\n",
              " 'accents',\n",
              " 'accept',\n",
              " 'acceptable',\n",
              " 'accepted',\n",
              " 'accepting',\n",
              " 'access',\n",
              " 'accessed',\n",
              " 'accessible',\n",
              " 'accessory',\n",
              " 'accident',\n",
              " 'accidental',\n",
              " 'accidentally',\n",
              " 'accidently',\n",
              " 'accidents',\n",
              " 'accommodate',\n",
              " 'accompanied',\n",
              " 'accompany',\n",
              " 'accompanying',\n",
              " 'accomplices',\n",
              " 'accomplish',\n",
              " 'accomplished',\n",
              " 'accomplishment',\n",
              " 'accorded',\n",
              " 'according',\n",
              " 'account',\n",
              " 'accountant',\n",
              " 'accounted',\n",
              " 'accounting',\n",
              " 'accounts',\n",
              " 'accumulate',\n",
              " 'accurate',\n",
              " 'accusation',\n",
              " 'accuse',\n",
              " 'accused',\n",
              " 'accusing',\n",
              " 'accustomed',\n",
              " 'ace',\n",
              " 'aced',\n",
              " 'aces',\n",
              " 'ach',\n",
              " 'ache',\n",
              " 'aches',\n",
              " 'achieve',\n",
              " 'achievement',\n",
              " 'achilles',\n",
              " 'acid',\n",
              " 'ackerman',\n",
              " 'acknowledge',\n",
              " 'acknowledged',\n",
              " 'acknowledging',\n",
              " 'acl',\n",
              " 'acme',\n",
              " 'acmes',\n",
              " 'acoming',\n",
              " 'acquaintance',\n",
              " 'acquainted',\n",
              " 'acquire',\n",
              " 'acquired',\n",
              " 'acquisition',\n",
              " 'acquisitions',\n",
              " 'acre',\n",
              " 'acres',\n",
              " 'acribus',\n",
              " 'acrobat',\n",
              " 'acrophobia',\n",
              " 'across',\n",
              " 'acrost',\n",
              " 'act',\n",
              " 'acted',\n",
              " 'acting',\n",
              " 'action',\n",
              " 'actions',\n",
              " 'activate',\n",
              " 'activated',\n",
              " 'activation',\n",
              " 'active',\n",
              " 'activities',\n",
              " 'activity',\n",
              " 'actor',\n",
              " 'actors',\n",
              " 'actress',\n",
              " 'actresses',\n",
              " 'acts',\n",
              " 'actual',\n",
              " 'actuality',\n",
              " 'actually',\n",
              " 'acute',\n",
              " 'ad',\n",
              " 'ada',\n",
              " 'adagio',\n",
              " 'adam',\n",
              " 'adamant',\n",
              " 'adams',\n",
              " 'adapt',\n",
              " 'adcox',\n",
              " 'add',\n",
              " 'added',\n",
              " 'addict',\n",
              " 'addicted',\n",
              " 'addiction',\n",
              " 'addictis',\n",
              " 'addicts',\n",
              " 'adding',\n",
              " 'addison',\n",
              " 'addition',\n",
              " 'additional',\n",
              " 'address',\n",
              " 'addressed',\n",
              " 'addressing',\n",
              " 'adds',\n",
              " 'adele',\n",
              " 'adelle',\n",
              " 'adenoids',\n",
              " 'adios',\n",
              " 'adjectives',\n",
              " 'adjust',\n",
              " 'adjusted',\n",
              " 'adjusting',\n",
              " 'adjustment',\n",
              " 'adjustments',\n",
              " 'adm',\n",
              " 'administer',\n",
              " 'administered',\n",
              " 'administering',\n",
              " 'administration',\n",
              " 'administrator',\n",
              " 'admiral',\n",
              " 'admirals',\n",
              " 'admiration',\n",
              " 'admire',\n",
              " 'admired',\n",
              " 'admirer',\n",
              " 'admirers',\n",
              " 'admiring',\n",
              " 'admission',\n",
              " 'admissions',\n",
              " 'admit',\n",
              " 'admits',\n",
              " 'admittance',\n",
              " 'admitted',\n",
              " 'admitting',\n",
              " 'adolf',\n",
              " 'adolph',\n",
              " 'adonai',\n",
              " 'adopt',\n",
              " 'adopted',\n",
              " 'adoption',\n",
              " 'adorable',\n",
              " 'adore',\n",
              " 'adrenaline',\n",
              " 'adrian',\n",
              " 'adriangs',\n",
              " 'adrift',\n",
              " 'ads',\n",
              " 'adult',\n",
              " 'adults',\n",
              " 'advance',\n",
              " 'advanced',\n",
              " 'advancement',\n",
              " 'advances',\n",
              " 'advantage',\n",
              " 'advantages',\n",
              " 'adventure',\n",
              " 'adventurous',\n",
              " 'adversary',\n",
              " 'advertising',\n",
              " 'advice',\n",
              " 'advisable',\n",
              " 'advise',\n",
              " 'advised',\n",
              " 'advisor',\n",
              " 'aesthetic',\n",
              " 'affair',\n",
              " 'affairs',\n",
              " 'affect',\n",
              " 'affected',\n",
              " 'affecting',\n",
              " 'affection',\n",
              " 'affirmative',\n",
              " 'afford',\n",
              " 'affraid',\n",
              " 'afire',\n",
              " 'afraid',\n",
              " 'africa',\n",
              " 'african',\n",
              " 'africanamerican',\n",
              " 'aft',\n",
              " 'afta',\n",
              " 'after',\n",
              " 'afterlife',\n",
              " 'aftermath',\n",
              " 'afternoon',\n",
              " 'afterschool',\n",
              " 'afterward',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'agatha',\n",
              " 'age',\n",
              " 'aged',\n",
              " 'agency',\n",
              " 'agenda',\n",
              " 'agent',\n",
              " 'agents',\n",
              " 'ages',\n",
              " 'aggravation',\n",
              " 'aggressive',\n",
              " 'agh',\n",
              " 'aging',\n",
              " 'agitated',\n",
              " 'agitators',\n",
              " 'agnes',\n",
              " 'ago',\n",
              " 'agoing',\n",
              " 'agonizing',\n",
              " 'agony',\n",
              " 'agree',\n",
              " 'agreed',\n",
              " 'agreeing',\n",
              " 'agreement',\n",
              " 'agreements',\n",
              " 'agrees',\n",
              " 'agronomist',\n",
              " 'ah',\n",
              " 'aha',\n",
              " 'ahead',\n",
              " 'ahem',\n",
              " 'ahh',\n",
              " 'ahha',\n",
              " 'ahhah',\n",
              " 'ahhh',\n",
              " 'ahhhh',\n",
              " 'ahhhhhh',\n",
              " 'ahi',\n",
              " 'ahm',\n",
              " 'ahold',\n",
              " 'ai',\n",
              " 'aid',\n",
              " 'aide',\n",
              " 'aiding',\n",
              " 'aids',\n",
              " 'aim',\n",
              " 'aiming',\n",
              " 'ainge',\n",
              " 'aint',\n",
              " 'air',\n",
              " 'airborne',\n",
              " 'aircraft',\n",
              " 'airlift',\n",
              " 'airline',\n",
              " 'airlines',\n",
              " 'airlock',\n",
              " 'airplane',\n",
              " 'airport',\n",
              " 'airs',\n",
              " 'airsick',\n",
              " 'airspace',\n",
              " 'ais',\n",
              " 'aisle',\n",
              " 'aka',\n",
              " 'akron',\n",
              " 'al',\n",
              " 'alabama',\n",
              " 'alai',\n",
              " 'alain',\n",
              " 'alamo',\n",
              " 'alan',\n",
              " 'alangs',\n",
              " 'alanone',\n",
              " 'alarm',\n",
              " 'alarmed',\n",
              " 'alarms',\n",
              " 'alas',\n",
              " 'alaska',\n",
              " 'albacore',\n",
              " 'albania',\n",
              " 'albanian',\n",
              " 'albany',\n",
              " 'albert',\n",
              " 'alberts',\n",
              " 'albino',\n",
              " 'albrecht',\n",
              " 'album',\n",
              " 'alcohol',\n",
              " 'alcoholic',\n",
              " 'ale',\n",
              " 'alert',\n",
              " 'alerted',\n",
              " 'alex',\n",
              " 'alexander',\n",
              " 'alexandria',\n",
              " 'alexs',\n",
              " 'alfonse',\n",
              " 'alfred',\n",
              " 'alfredo',\n",
              " 'alfreds',\n",
              " 'algeria',\n",
              " 'algiers',\n",
              " 'ali',\n",
              " 'alibi',\n",
              " 'alibis',\n",
              " 'alice',\n",
              " 'alien',\n",
              " 'aliens',\n",
              " 'alignment',\n",
              " 'alike',\n",
              " 'alimony',\n",
              " 'alison',\n",
              " 'alito',\n",
              " 'alive',\n",
              " 'all',\n",
              " 'alla',\n",
              " 'allah',\n",
              " 'allan',\n",
              " 'alleged',\n",
              " 'allegedly',\n",
              " 'allegiance',\n",
              " 'allen',\n",
              " 'allergic',\n",
              " 'allergy',\n",
              " 'alles',\n",
              " 'alley',\n",
              " 'alleys',\n",
              " 'alleyway',\n",
              " 'allie',\n",
              " 'allies',\n",
              " 'alligator',\n",
              " 'allison',\n",
              " 'allo',\n",
              " 'allow',\n",
              " 'allowance',\n",
              " 'allowed',\n",
              " 'allowing',\n",
              " 'allows',\n",
              " 'alloy',\n",
              " 'allright',\n",
              " 'alls',\n",
              " 'allstars',\n",
              " 'allstate',\n",
              " 'allus',\n",
              " 'ally',\n",
              " 'alma',\n",
              " 'almanac',\n",
              " 'almighty',\n",
              " 'almost',\n",
              " 'almsy',\n",
              " 'aloha',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'alongside',\n",
              " 'alonzo',\n",
              " 'alors',\n",
              " 'alot',\n",
              " 'alotta',\n",
              " 'aloud',\n",
              " 'alpha',\n",
              " 'alphabet',\n",
              " 'alpine',\n",
              " 'alps',\n",
              " 'already',\n",
              " 'alright',\n",
              " 'also',\n",
              " 'altar',\n",
              " 'alter',\n",
              " 'alterations',\n",
              " 'altered',\n",
              " 'altering',\n",
              " 'alternate',\n",
              " 'alternative',\n",
              " 'alternatives',\n",
              " 'alternator',\n",
              " 'althea',\n",
              " 'although',\n",
              " 'altitude',\n",
              " 'altogether',\n",
              " 'alvarez',\n",
              " 'alvin',\n",
              " 'alvy',\n",
              " 'always',\n",
              " 'alyssa',\n",
              " 'am',\n",
              " 'amado',\n",
              " 'amanda',\n",
              " 'amarillo',\n",
              " 'amateur',\n",
              " 'amateurs',\n",
              " 'amaze',\n",
              " 'amazed',\n",
              " 'amazes',\n",
              " 'amazing',\n",
              " 'ambassador',\n",
              " 'ambassadors',\n",
              " 'amber',\n",
              " 'ambition',\n",
              " 'ambitious',\n",
              " 'ambrose',\n",
              " 'ambulance',\n",
              " 'ambush',\n",
              " 'ambushed',\n",
              " 'amen',\n",
              " 'amendment',\n",
              " 'amends',\n",
              " 'america',\n",
              " 'american',\n",
              " 'americans',\n",
              " 'americas',\n",
              " 'ames',\n",
              " 'ami',\n",
              " 'amigo',\n",
              " 'amish',\n",
              " 'amiss',\n",
              " 'amity',\n",
              " 'amma',\n",
              " 'ammo',\n",
              " 'ammunition',\n",
              " 'amnesia',\n",
              " 'amo',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'amos',\n",
              " 'amount',\n",
              " 'amounts',\n",
              " 'amp',\n",
              " 'ample',\n",
              " 'amsick',\n",
              " 'amsterdam',\n",
              " 'amu',\n",
              " 'amuse',\n",
              " 'amused',\n",
              " 'amusement',\n",
              " 'amusing',\n",
              " 'amy',\n",
              " 'an',\n",
              " 'anacott',\n",
              " 'anal',\n",
              " 'analogy',\n",
              " 'analysis',\n",
              " 'analyst',\n",
              " 'analytic',\n",
              " 'analyze',\n",
              " 'analyzed',\n",
              " 'analyzing',\n",
              " 'anarchy',\n",
              " 'anastasia',\n",
              " 'anatomy',\n",
              " 'ancestors',\n",
              " 'anchor',\n",
              " 'ancient',\n",
              " 'and',\n",
              " 'andand',\n",
              " 'andandand',\n",
              " 'anders',\n",
              " 'anderson',\n",
              " 'anderton',\n",
              " 'andre',\n",
              " 'andrew',\n",
              " 'andrews',\n",
              " 'android',\n",
              " 'androids',\n",
              " 'andy',\n",
              " 'andys',\n",
              " 'anemic',\n",
              " 'anesthesia',\n",
              " 'anesthesiologist',\n",
              " 'anesthesiology',\n",
              " 'anesthetic',\n",
              " 'anesthetics',\n",
              " 'aneurysm',\n",
              " 'ang',\n",
              " 'angel',\n",
              " 'angela',\n",
              " 'angeles',\n",
              " 'angelo',\n",
              " 'angels',\n",
              " 'anger',\n",
              " 'angie',\n",
              " 'angle',\n",
              " 'angles',\n",
              " 'anglo',\n",
              " 'angora',\n",
              " 'angry',\n",
              " 'animal',\n",
              " 'animals',\n",
              " 'anita',\n",
              " 'ankle',\n",
              " 'ankles',\n",
              " 'ann',\n",
              " 'anna',\n",
              " 'annabelle',\n",
              " 'annabelles',\n",
              " 'annas',\n",
              " 'anne',\n",
              " 'annes',\n",
              " 'annette',\n",
              " 'annex',\n",
              " 'annie',\n",
              " 'annies',\n",
              " 'anniversary',\n",
              " 'announce',\n",
              " 'announced',\n",
              " 'announcement',\n",
              " 'announcing',\n",
              " 'annoy',\n",
              " 'annoying',\n",
              " 'annual',\n",
              " 'annulled',\n",
              " 'anomalies',\n",
              " 'anomaly',\n",
              " 'anon',\n",
              " 'anonymity',\n",
              " 'anonymous',\n",
              " 'another',\n",
              " 'ansel',\n",
              " 'answer',\n",
              " 'answered',\n",
              " 'answering',\n",
              " 'answers',\n",
              " 'ant',\n",
              " 'antagonize',\n",
              " 'antenna',\n",
              " 'antennae',\n",
              " 'anthony',\n",
              " 'anthonys',\n",
              " 'anti',\n",
              " 'antichrist',\n",
              " 'anticipate',\n",
              " 'anticipated',\n",
              " 'anticipation',\n",
              " 'antidote',\n",
              " 'antigua',\n",
              " 'antimatter',\n",
              " 'antique',\n",
              " 'antiques',\n",
              " 'antisemitism',\n",
              " 'antitoxin',\n",
              " 'anton',\n",
              " 'antonia',\n",
              " 'antonio',\n",
              " 'ants',\n",
              " 'antsy',\n",
              " 'anubis',\n",
              " 'anus',\n",
              " 'anxiety',\n",
              " 'anxious',\n",
              " 'any',\n",
              " 'anya',\n",
              " 'anybody',\n",
              " 'anybodys',\n",
              " 'anyhow',\n",
              " 'anymore',\n",
              " 'anyone',\n",
              " 'anyones',\n",
              " 'anyplace',\n",
              " 'anyroad',\n",
              " 'anything',\n",
              " 'anythings',\n",
              " 'anytime',\n",
              " 'anyway',\n",
              " 'anyways',\n",
              " 'anywhere',\n",
              " 'aokay',\n",
              " 'apache',\n",
              " 'apart',\n",
              " 'apartment',\n",
              " 'apartments',\n",
              " 'apb',\n",
              " 'ape',\n",
              " 'apes',\n",
              " 'aphrodite',\n",
              " 'apiece',\n",
              " 'apipoussan',\n",
              " 'apollo',\n",
              " 'apologies',\n",
              " 'apologize',\n",
              " 'apologized',\n",
              " 'apologizing',\n",
              " 'apology',\n",
              " 'apparatus',\n",
              " 'apparent',\n",
              " 'apparently',\n",
              " 'appeal',\n",
              " 'appealing',\n",
              " 'appear',\n",
              " 'appearance',\n",
              " 'appearances',\n",
              " 'appeared',\n",
              " 'appearing',\n",
              " 'appears',\n",
              " 'appendix',\n",
              " 'appetite',\n",
              " 'applause',\n",
              " 'apple',\n",
              " 'applejack',\n",
              " 'apples',\n",
              " 'appleton',\n",
              " 'appliance',\n",
              " 'appliances',\n",
              " 'applicant',\n",
              " 'application',\n",
              " 'applications',\n",
              " 'applied',\n",
              " 'apply',\n",
              " 'applying',\n",
              " 'appoint',\n",
              " 'appointed',\n",
              " 'appointment',\n",
              " 'appointments',\n",
              " 'appreciate',\n",
              " 'appreciated',\n",
              " 'appreciates',\n",
              " 'appreciation',\n",
              " 'apprehensive',\n",
              " 'apprentice',\n",
              " 'approach',\n",
              " 'approached',\n",
              " 'approaches',\n",
              " 'approaching',\n",
              " 'appropriate',\n",
              " 'approval',\n",
              " 'approve',\n",
              " 'approved',\n",
              " 'approximately',\n",
              " 'april',\n",
              " 'apron',\n",
              " 'apt',\n",
              " 'aquarium',\n",
              " 'aqui',\n",
              " 'arabia',\n",
              " 'arabic',\n",
              " 'arabs',\n",
              " 'araby',\n",
              " 'aramis',\n",
              " 'arbitrary',\n",
              " 'arbogast',\n",
              " 'arbor',\n",
              " 'arc',\n",
              " 'arcade',\n",
              " 'arch',\n",
              " 'archangel',\n",
              " 'archbishop',\n",
              " 'archdiocese',\n",
              " 'archeological',\n",
              " 'archer',\n",
              " 'archie',\n",
              " 'architect',\n",
              " 'architects',\n",
              " 'architecture',\n",
              " 'archive',\n",
              " 'archives',\n",
              " 'archuh',\n",
              " 'arctic',\n",
              " 'ardelia',\n",
              " 'are',\n",
              " 'area',\n",
              " 'areare',\n",
              " 'areas',\n",
              " 'arei',\n",
              " 'arena',\n",
              " 'arent',\n",
              " 'arethe',\n",
              " 'arethey',\n",
              " 'areu',\n",
              " 'areyou',\n",
              " 'argentina',\n",
              " 'argo',\n",
              " 'argon',\n",
              " 'argongs',\n",
              " 'argue',\n",
              " 'arguing',\n",
              " 'argument',\n",
              " 'argumentative',\n",
              " 'arguments',\n",
              " 'argyle',\n",
              " 'aria',\n",
              " 'arise',\n",
              " 'aristocrat',\n",
              " 'aristotle',\n",
              " 'arithmetic',\n",
              " 'arizona',\n",
              " 'ark',\n",
              " 'arkansas',\n",
              " 'arlene',\n",
              " 'arletta',\n",
              " 'arlington',\n",
              " 'arlo',\n",
              " 'arlyn',\n",
              " 'arm',\n",
              " 'armada',\n",
              " 'armand',\n",
              " 'armani',\n",
              " 'armed',\n",
              " 'armitage',\n",
              " 'armor',\n",
              " 'armored',\n",
              " 'arms',\n",
              " 'armstrong',\n",
              " 'army',\n",
              " 'armys',\n",
              " 'arnie',\n",
              " 'arnold',\n",
              " 'aron',\n",
              " 'around',\n",
              " 'arounna',\n",
              " 'arouse',\n",
              " 'aroused',\n",
              " 'arousing',\n",
              " 'arrange',\n",
              " 'arranged',\n",
              " 'arrangement',\n",
              " 'arrangements',\n",
              " 'arranging',\n",
              " 'arrest',\n",
              " 'arrested',\n",
              " 'arresting',\n",
              " 'arrests',\n",
              " 'arrival',\n",
              " 'arrive',\n",
              " 'arrived',\n",
              " 'arrives',\n",
              " 'arriving',\n",
              " 'arrogance',\n",
              " 'arrogant',\n",
              " 'arrow',\n",
              " 'arroway',\n",
              " 'arrows',\n",
              " 'arse',\n",
              " 'arson',\n",
              " 'arsonist',\n",
              " 'art',\n",
              " 'artemus',\n",
              " 'arterial',\n",
              " 'artery',\n",
              " 'arthritis',\n",
              " 'arthur',\n",
              " 'arthurs',\n",
              " 'article',\n",
              " 'articles',\n",
              " 'artie',\n",
              " 'artifacts',\n",
              " 'artificial',\n",
              " 'artificially',\n",
              " 'artillery',\n",
              " 'artist',\n",
              " 'artistic',\n",
              " 'artists',\n",
              " 'artoo',\n",
              " 'arts',\n",
              " 'aryan',\n",
              " 'as',\n",
              " 'asap',\n",
              " 'asbestos',\n",
              " 'ascension',\n",
              " 'asgaard',\n",
              " 'ash',\n",
              " 'ashamed',\n",
              " 'ashes',\n",
              " 'ashley',\n",
              " 'ashore',\n",
              " 'ashtray',\n",
              " 'asia',\n",
              " 'asian',\n",
              " 'aside',\n",
              " 'ask',\n",
              " 'asked',\n",
              " 'asking',\n",
              " 'asks',\n",
              " 'asleen',\n",
              " 'asleep',\n",
              " 'aspect',\n",
              " 'aspen',\n",
              " 'aspirated',\n",
              " 'aspirin',\n",
              " 'aspirins',\n",
              " 'ass',\n",
              " 'assa',\n",
              " 'assassin',\n",
              " 'assassinate',\n",
              " 'assassination',\n",
              " 'assassins',\n",
              " 'assault',\n",
              " 'assemble',\n",
              " 'assembled',\n",
              " 'assembling',\n",
              " 'assembly',\n",
              " 'asses',\n",
              " 'assess',\n",
              " 'assessment',\n",
              " 'asset',\n",
              " 'assets',\n",
              " 'assface',\n",
              " 'asshole',\n",
              " 'assholes',\n",
              " 'assign',\n",
              " 'assigned',\n",
              " 'assignment',\n",
              " 'assignments',\n",
              " 'assist',\n",
              " 'assistance',\n",
              " 'assistant',\n",
              " 'assistants',\n",
              " 'assisting',\n",
              " 'associate',\n",
              " 'associated',\n",
              " 'associates',\n",
              " 'association',\n",
              " 'assume',\n",
              " 'assumed',\n",
              " 'assuming',\n",
              " 'assumption',\n",
              " 'assumptions',\n",
              " 'assurance',\n",
              " 'assure',\n",
              " 'assured',\n",
              " 'ast',\n",
              " 'asta',\n",
              " 'astaying',\n",
              " 'astern',\n",
              " 'asteroid',\n",
              " 'asthma',\n",
              " 'astonishing',\n",
              " 'asylum',\n",
              " 'at',\n",
              " 'atatatatat',\n",
              " 'ate',\n",
              " 'atf',\n",
              " 'atheist',\n",
              " 'athlete',\n",
              " 'athletes',\n",
              " 'athletic',\n",
              " 'athos',\n",
              " 'atkins',\n",
              " 'atlanta',\n",
              " 'atlantic',\n",
              " 'atlantis',\n",
              " 'atley',\n",
              " 'atm',\n",
              " 'atmosphere',\n",
              " 'atmospheric',\n",
              " 'atom',\n",
              " 'atomic',\n",
              " 'atrocious',\n",
              " 'atsa',\n",
              " 'att',\n",
              " 'atta',\n",
              " 'attached',\n",
              " 'attack',\n",
              " 'attacked',\n",
              " 'attacking',\n",
              " 'attacks',\n",
              " 'attempt',\n",
              " 'attempted',\n",
              " 'attempting',\n",
              " 'attempts',\n",
              " 'attend',\n",
              " 'attendance',\n",
              " 'attendant',\n",
              " 'attendants',\n",
              " 'attended',\n",
              " 'attending',\n",
              " 'attention',\n",
              " 'attic',\n",
              " 'attica',\n",
              " 'attire',\n",
              " 'attitude',\n",
              " 'attorney',\n",
              " 'attorneys',\n",
              " 'attract',\n",
              " 'attracted',\n",
              " 'attraction',\n",
              " 'attractions',\n",
              " 'attractive',\n",
              " 'au',\n",
              " 'aubrey',\n",
              " 'auction',\n",
              " 'audience',\n",
              " 'audiences',\n",
              " 'audition',\n",
              " 'auditioning',\n",
              " 'auditions',\n",
              " 'auditorium',\n",
              " 'audrey',\n",
              " 'auggie',\n",
              " 'august',\n",
              " 'augusto',\n",
              " 'aunt',\n",
              " 'auntie',\n",
              " 'aunts',\n",
              " 'aus',\n",
              " 'austin',\n",
              " 'australia',\n",
              " 'australian',\n",
              " 'austria',\n",
              " 'austrian',\n",
              " 'authentic',\n",
              " 'author',\n",
              " 'authorities',\n",
              " 'authority',\n",
              " 'authorization',\n",
              " 'authorize',\n",
              " 'authorized',\n",
              " 'authors',\n",
              " 'auto',\n",
              " 'autograph',\n",
              " 'automated',\n",
              " 'automatic',\n",
              " 'automatically',\n",
              " 'automobile',\n",
              " 'autopilot',\n",
              " 'autopsy',\n",
              " 'autoshop',\n",
              " 'auxiliary',\n",
              " 'available',\n",
              " 'avanti',\n",
              " 'avec',\n",
              " 'avenge',\n",
              " 'avenue',\n",
              " 'average',\n",
              " 'aversion',\n",
              " 'avery',\n",
              " 'aviation',\n",
              " 'avocado',\n",
              " 'avoid',\n",
              " 'avoided',\n",
              " 'avoiding',\n",
              " 'aw',\n",
              " 'await',\n",
              " 'awaiting',\n",
              " 'awaits',\n",
              " 'awake',\n",
              " 'awaken',\n",
              " 'awakened',\n",
              " 'award',\n",
              " 'awards',\n",
              " 'aware',\n",
              " 'away',\n",
              " 'awe',\n",
              " 'awesome',\n",
              " 'awful',\n",
              " 'awfully',\n",
              " 'awfuls',\n",
              " 'awhile',\n",
              " 'awkward',\n",
              " 'awright',\n",
              " 'aww',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5kC5nN073cL",
        "outputId": "5cab7a89-d05c-4aad-bf56-4a824f630721"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "vocab_len = len(short_vocab) + 1\n",
        "vocab_len"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18595"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHHGOwse73cM",
        "outputId": "4f78ffaf-0301-45fa-9fcb-adf66623573f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "def trim_rare_words(vocab, pairs):\n",
        "    keep_pairs = []\n",
        "    i = 0\n",
        "    for pair in pairs:\n",
        "        i += 1\n",
        "        progressBar(value=i,endvalue=len(pairs))\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "\n",
        "        for word in input_sentence.split(' '):\n",
        "            if word not in vocab:\n",
        "                keep_input = False\n",
        "                break\n",
        "\n",
        "        for word in output_sentence.split(' '):\n",
        "            if word not in vocab:\n",
        "                keep_output = False\n",
        "                break\n",
        "        \n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "    \n",
        "    print('\\nPairs trimmed from {} pairs to {} pairs'.format(len(pairs), len(keep_pairs)))\n",
        "    return keep_pairs\n",
        "\n",
        "\n",
        "pairs_final = trim_rare_words(short_vocab, pairs_final)\n",
        "with open('final_pairs.pkl', 'wb') as f:\n",
        "    pairs_final = pickle.dump(pairs_final, f)\n",
        "\n",
        "with open('final_pairs.pkl', 'rb') as f:\n",
        "    pairs_final = pickle.load(f)\n",
        "\n",
        "pairs_final_train = pairs_final\n",
        "len(pairs_final_train)\n",
        "        "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job Completion: [------------------->] 100%\n",
            "Pairs trimmed from 180729 pairs to 143758 pairs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "143758"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7HSTVdo73cM",
        "outputId": "b18bf7d3-e425-4ee3-d889-2a4310e4eb1c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "# Tokenizing the texts\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(short_vocab)\n",
        "\n",
        "#index to word dictionary\n",
        "indextoword = {}\n",
        "#word to index dictionary\n",
        "wordtoindex = tokenizer.word_index\n",
        "pad_token = 'pad0'\n",
        "\n",
        "# no word in vocab has index 0. but padding is indicated with 0\n",
        "indextoword[0] = pad_token\n",
        "\n",
        "for w in tokenizer.word_index:\n",
        "    indextoword[tokenizer.word_index[w]] = w"
      ],
      "outputs": [],
      "metadata": {
        "id": "33hpLp2x73cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making the Model"
      ],
      "metadata": {
        "id": "cEESBgRv73cN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "# Making the Embedding Matrix\n",
        "def make_embedding_layer(embedding_dim = 100, glove = True):\n",
        "    # GloVe is an unsupervised learning algorithm for\n",
        "    # obtaining vector representations for words. Training\n",
        "    # is performed on aggregated global word-word\n",
        "    # co-occurrence statistics from a corpus, and the\n",
        "    # resulting representations showcase interesting linear\n",
        "    # substructures of the word vector space.\n",
        "    if glove == False:\n",
        "        print('Zero Matrix Loaded')\n",
        "        embedding_matrix = np.zeros((vocab_len, embedding_dim))\n",
        "    else:\n",
        "        print('Loading glove...')\n",
        "        glove_dir = './glove'\n",
        "        embeddings_index = {}\n",
        "        f = open('glove.6B.50d.txt', encoding='utf-8')\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "        f.close()\n",
        "        print(\"GloVe \", embedding_dim, 'loaded !')\n",
        "        # get 200-dim dense vector for each of the vocab_rocc\n",
        "        embedding_matrix = np.zeros((vocab_len, embedding_dim))\n",
        "        # to import as weights for Keras Embedding layer\n",
        "        for word, i in wordtoindex.items():\n",
        "            embedding_vector = embeddings_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                # Words not found in the embedding index will be all zeros\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    embedding_layer = Embedding(vocab_len, embedding_dim, mask_zero=True, trainable=False)\n",
        "    # we have a limited vocab so we\n",
        "    # do not train the embedding layer\n",
        "    # we use 0 as padding so => mask_zero = true\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([embedding_matrix])\n",
        "\n",
        "    return embedding_layer\n",
        "\n",
        "embeddings = make_embedding_layer(embedding_dim = emb_dim, glove=not test)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading glove...\n",
            "GloVe  50 loaded !\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON1IwfVn73cN",
        "outputId": "5b689d32-9355-4148-b135-df53e5817031"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_size\n",
        "        self.enc_units = enc_units\n",
        "        self.embeddings = embeddings\n",
        "\n",
        "        self.Bidirectional1 = Bidirectional(GRU(enc_units, return_sequences=True, return_state=False, recurrent_initializer='glorot_uniform', name='gru_1'), name='bidirectional_encoder1')\n",
        "        self.Bidirectional2 = Bidirectional(GRU(enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform', name='gru_2'), name='bidirectional_encoder2')\n",
        "\n",
        "        self.dropout = Dropout(0.2)\n",
        "        # imput layer size is same as that of max question length\n",
        "        self.Inp = Input(shape=(max_len_ques,))\n",
        "\n",
        "    def bidirectional(self, bidir, layer, inp, hidden):\n",
        "        return bidir(layer(inp, initial_state= hidden))\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        output, state_f, state_b = self.Bidirectional2(x)\n",
        "\n",
        "        return output, state_f, state_b\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "outputs": [],
      "metadata": {
        "id": "zSrJ0Tyq73cO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "encoder = Encoder(vocab_len, emb_dim, GRU_units)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y7srWqPm73cO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        self.units = units\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "outputs": [],
      "metadata": {
        "id": "SKyIYrOs73cO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_size\n",
        "        self.embeddings = embeddings\n",
        "\n",
        "        #since we are using a bidirectional encoder\n",
        "        self.units = 2 * dec_units\n",
        "        self.fc = Dense(vocab_len, activation='softmax', name='dense_layer')\n",
        "        #used for attention\n",
        "        self.attention = BahdanauAttention(self.units)\n",
        "        self.decoder_gru_l1 = GRU(self.units, return_sequences=True, return_state=False, recurrent_initializer='glorot_uniform', name='decoder_gru1')\n",
        "        self.decoder_gru_l2 = GRU(self.units, return_sequences=False, return_state=True, recurrent_initializer='glorot_uniform', name='decoder_gru2')\n",
        "        self.dropout = Dropout(0.4)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "        x = self.embeddings(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        x = self.decoder_gru_l1(x)\n",
        "        x = self.dropout(x)\n",
        "        output, state = self.decoder_gru_l2(x)\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "outputs": [],
      "metadata": {
        "id": "HhpvgaQx73cP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "decoder = Decoder(vocab_len, emb_dim, GRU_units)"
      ],
      "outputs": [],
      "metadata": {
        "id": "DkD6z5zY73cP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replying to Questions"
      ],
      "metadata": {
        "id": "qNz4kDTh73cP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "import unicodedata\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZL-v40h973cP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_len_ans, max_len_ques))\n",
        "    sentence = unicode_to_ascii(sentence.lower())\n",
        "    inputs = [wordtoindex[i] for i in sentence.split(' ')]\n",
        "    inputs = [wordtoindex[start_token]] + inputs + [wordtoindex[end_token]]\n",
        "    inputs = pad_sequences([inputs], maxlen=max_len_ques, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, GRU_units))]\n",
        "    enc_out, enc_hidden_f, enc_hidden_b = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = Concatenate(axis=-1)([enc_hidden_f, enc_hidden_b])\n",
        "    dec_input = tf.expand_dims([wordtoindex[start_token]], 1)\n",
        "\n",
        "    for t in range(max_len_ans):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = K.get_value(attention_weights)\n",
        "        predicted_id = K.get_value(tf.argmax(predictions[0]))\n",
        "        if indextoword[predicted_id] == end_token:\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        result += indextoword[predicted_id] + ' '\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 1)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "outputs": [],
      "metadata": {
        "id": "CyOzv2NN73cP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    ax = fig.add_sublot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict = fontdict, rotation = 90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict = fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "ecd98-6N73cQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "def answer(sentence, training = False):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    if training:\n",
        "        return result\n",
        "\n",
        "    print('Input: ', sentence)\n",
        "    print('Predicted Answer: {}'.format(result))\n",
        "    attention_plot = attention_plot[1: len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' ')[:-1])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Cepbc4v473cQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "def beam_search(sentence, k = 3, maxsample = max_len_ans, use_unk = False, oov = None, eos = end_token):\n",
        "    \"\"\"\n",
        "    return k samples (beams) and their NLL scores, each sample is a sequence of labels,\n",
        "    all samples starts with an `empty` label and end with `eos` or truncated to length of `maxsample`.\n",
        "    You need to supply `predict` which returns the label probability of each sample.\n",
        "    `use_unk` allow usage of `oov` (out-of-vocabulary) label in samples\n",
        "    \"\"\"\n",
        "\n",
        "    dead_k = 0  #samples that reached eos\n",
        "    dead_samples = []\n",
        "    dead_scores = []\n",
        "\n",
        "    live_k = 1  #samples that did not reach eos\n",
        "    live_samples = [[wordtoindex[start_token]]]\n",
        "    live_scores = [0]\n",
        "\n",
        "    sentence = unicode_to_ascii(sentence.lower())\n",
        "    inputs = [wordtoindex[i] for i in sentence.split(' ')]\n",
        "    inputs = [wordtoindex[start_token]] + inputs + [wordtoindex[end_token]]\n",
        "    inputs = pad_sequences([inputs], maxlen=max_len_ques, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    hidden = [tf.zeros((1, GRU_units))]\n",
        "    enc_out, enc_hidden, end_hidden_b = encoder(inputs, hidden)\n",
        "    dec_hidden = Concatenate(axis=-1)([enc_hidden_f, end_hidden_b])\n",
        "    dec_input = tf.expand_dims([wordtoindex[start_token]], 0)\n",
        "\n",
        "    while live_k and dead_k < k:\n",
        "        # for every possible live sample calc prob for every possible label \n",
        "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_out)\n",
        "        probs = K.get_value(predictions[0])\n",
        "\n",
        "        cand_scores = np.array(live_scores)[:, None] - np.log(probs)\n",
        "\n",
        "        if not use_unk and oov is not None:\n",
        "            cand_scores[:, oov] = 1e20\n",
        "        \n",
        "        cand_flat = cand_scores.flatten()\n",
        "\n",
        "        # find the best (lowest) scores we have from all possible samples and new words\n",
        "        ranks_flat = cand_flat.argsort()[:(k - dead_k)]\n",
        "        live_scores - cand_flat[ranks_flat]\n",
        "\n",
        "         # append the new words to their appropriate live sample\n",
        "        voc_size = vocab_len\n",
        "        live_samples = [live_samples[r//voc_size] + [r%voc_size] for r in ranks_flat]\n",
        "\n",
        "         # live samples that should be dead are...\n",
        "        zombie = [s[-1] == eos or len(s) >= maxsample for s in live_samples]\n",
        "\n",
        "        # add zombies to the dead\n",
        "        dead_samples += [s for s,z in zip(live_samples,zombie) if z]  # remove first label == empty\n",
        "        dead_scores += [s for s,z in zip(live_scores,zombie) if z]\n",
        "        dead_k = len(dead_samples)\n",
        "        # remove zombies from the living \n",
        "        live_samples = [s for s,z in zip(live_samples,zombie) if not z]\n",
        "        live_scores = [s for s,z in zip(live_scores,zombie) if not z]\n",
        "        live_k = len(live_samples)\n",
        "\n",
        "    final_samples = dead_samples + live_samples\n",
        "    final_scores = dead_scores + live_scores   \n",
        "    \n",
        "    # cutting the strong where end_token is encounterd\n",
        "    for i in range(len(final_scores)):\n",
        "        final_scores[i] /= len(final_samples[i]) # normalizing the scores\n",
        "    \n",
        "    final_result =[]\n",
        "    \n",
        "    for i in range(len(final_scores)):\n",
        "        final_result.append((final_scores[i],final_samples[i]))\n",
        "    \n",
        "    final_list_ix = max(final_result)[1]\n",
        "    final_list_word = [ixtoword[f] for f in final_list_ix]\n",
        "    final_sentence = ' '.join(final_list_word[1:])\n",
        "    end_ix = final_sentence.find(end_token)\n",
        "    return final_sentence[:end_ix]\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "u854s-WC73cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Optimizer and Loss Function"
      ],
      "metadata": {
        "id": "fgwKoAHn73cQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "optimizer = tf.keras.optimizers.Adam(init_lr)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = K.sparse_categorical_crossentropy(real, pred, from_logits=False)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "outputs": [],
      "metadata": {
        "id": "G5_njMYA73cR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "1. Pass the *input* through the *encoder* which returns *encoder output* and the *encoder hidden state*.\n",
        "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
        "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
        "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "5. Use *teacher forcing* to decide the next input to the decoder.\n",
        "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
        "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ],
      "metadata": {
        "id": "4l0qUEAe73cR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden_f, enc_hidden_b = encoder(inp, enc_hidden)\n",
        "        dec_hidden = Concatenate(axis=-1)([enc_hidden_f, enc_hidden_b])\n",
        "        dec_input = tf.expand_dims([wordtoindex[start_token]] * batch_size , 1)\n",
        "\n",
        "         # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            #passing enc_output to decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "             # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "             # expected output at this time becomes input for next timestep\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "    "
      ],
      "outputs": [],
      "metadata": {
        "id": "0iArKVAd73cR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "history = {'loss':[]}\n",
        "smallest_loss = np.inf\n",
        "best_ep = 1\n",
        "EPOCHS = 200\n",
        "enc_hidden = encoder.initialize_hidden_state()\n",
        "steps_per_epoch = len(pairs_final_train)//batch_size\n",
        "\n",
        "current_ep = 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "-bqwvMRn73cR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "def test_bot(k = 3, beam = False):\n",
        "    print('#'*20)\n",
        "    q = 'Hello'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'Hey what is up'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'How are you doing'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q= 'Will you be my friend'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'What are you doing right now'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'What is your favorite restaurant'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'What is your favorite movie'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'What is your favorite country'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'Who are you'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'Do you want to go out with me'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('%')\n",
        "    q = 'What came first eggs or chickens'\n",
        "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
        "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
        "    print('#'*50)"
      ],
      "outputs": [],
      "metadata": {
        "id": "G9b8b3wC73cR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "def plot_history():\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    plt.plot(best_ep, smallest_loss, 'ro')\n",
        "    plt.plot(history['loss'], 'b-')\n",
        "    plt.legend(['best', 'loss'])\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "KP8PiNIL73cS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "batch_loss = K.constant(0)\n",
        "X, y = [], []\n",
        "\n",
        "for ep in range(current_ep, EPOCHS):\n",
        "    current_ep = ep\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "    btch = 1\n",
        "\n",
        "    for p in pairs_final_train:\n",
        "\n",
        "        question = p[0]\n",
        "        label = p[1]\n",
        "\n",
        "        # find the index of each word of the caption in vocabulary\n",
        "        question_seq = [wordtoindex[word] for word in question.split(' ') if word in wordtoindex]\n",
        "        label_seq = [wordtoindex[word] for word in label.split(' ') if word in wordtoindex]\n",
        "\n",
        "        # encoder input and decoder input and label\n",
        "        enc_in_seq = pad_sequences([question_seq], maxlen=max_len_ques, padding='post')[0]\n",
        "        dec_out_seq = pad_sequences([label_seq], maxlen=max_len_ans, padding='post')[0]\n",
        "\n",
        "        X.append(enc_in_seq)\n",
        "        y.append(dec_out_seq)\n",
        "\n",
        "        if len(X) == batch_size:\n",
        "            batch_loss = train_step(np.array(X), np.array(y), enc_hidden)\n",
        "            total_loss += batch_loss\n",
        "            X, y = [], []\n",
        "            btch +=1\n",
        "\n",
        "            if btch % (steps_per_epoch//6) == 0:\n",
        "                print('Epoch: {} Batch: {} Loss: {:.4f}'.format(ep, btch, K.get_value(batch_loss)))\n",
        "\n",
        "    epoch_loss = K.get_value(total_loss) / steps_per_epoch\n",
        "    print('Epoch: {} Batch: {} Loss: {:.4f}'.format(ep, btch, K.get_value(epoch_loss)))\n",
        "\n",
        "    history['loss'].append(epoch_loss)\n",
        "    \n",
        "    test_bot(k=5)\n",
        "\n",
        "    if epoch_loss < smallest_loss:\n",
        "        smallest_loss = epoch_loss\n",
        "        best_ep = ep\n",
        "        print('Checkpoint Saved!')\n",
        "\n",
        "    if  ep % 3 == 0:\n",
        "        plot_history()\n",
        "\n",
        "    print('Best epoch so far: ',best_ep,' smallest loss:',smallest_loss)\n",
        "    print('Time taken for the epoch {:.4f} sec\\n'.format(time.time() - start))\n",
        "\n",
        "    print('=' * 40)   "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Batch: 748 Loss: 1.3597\n",
            "Epoch: 1 Batch: 1496 Loss: 1.5935\n",
            "Epoch: 1 Batch: 2244 Loss: 1.8048\n",
            "Epoch: 1 Batch: 2992 Loss: 1.6749\n",
            "Epoch: 1 Batch: 3740 Loss: 1.5479\n",
            "Epoch: 1 Batch: 4488 Loss: 1.4950\n",
            "Epoch: 1 Batch: 4493 Loss: 1.4597\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: i am not you to do \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  1  smallest loss: 1.4597328845030053\n",
            "Time taken for the epoch 689.1517 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 2 Batch: 748 Loss: 1.4583\n",
            "Epoch: 2 Batch: 1496 Loss: 1.8460\n",
            "Epoch: 2 Batch: 2244 Loss: 1.7736\n",
            "Epoch: 2 Batch: 2992 Loss: 1.5817\n",
            "Epoch: 2 Batch: 3740 Loss: 1.4962\n",
            "Epoch: 2 Batch: 4488 Loss: 1.6864\n",
            "Epoch: 2 Batch: 4493 Loss: 1.4196\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not going to be a good time \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: i am not you \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  2  smallest loss: 1.4196147969654385\n",
            "Time taken for the epoch 689.0070 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 3 Batch: 748 Loss: 1.3693\n",
            "Epoch: 3 Batch: 1496 Loss: 2.1333\n",
            "Epoch: 3 Batch: 2244 Loss: 1.7025\n",
            "Epoch: 3 Batch: 2992 Loss: 1.7838\n",
            "Epoch: 3 Batch: 3740 Loss: 1.4069\n",
            "Epoch: 3 Batch: 4488 Loss: 1.4923\n",
            "Epoch: 3 Batch: 4494 Loss: 1.3856\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not going to do \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: i am not you \n",
            "##################################################\n",
            "Checkpoint Saved!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch so far:  3  smallest loss: 1.3856126168744434\n",
            "Time taken for the epoch 691.3063 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 4 Batch: 748 Loss: 1.2022\n",
            "Epoch: 4 Batch: 1496 Loss: 1.6150\n",
            "Epoch: 4 Batch: 2244 Loss: 1.6747\n",
            "Epoch: 4 Batch: 2992 Loss: 1.6394\n",
            "Epoch: 4 Batch: 3740 Loss: 1.4563\n",
            "Epoch: 4 Batch: 4488 Loss: 1.3583\n",
            "Epoch: 4 Batch: 4493 Loss: 1.3557\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not going to be a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not going to be a good time \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not going to do \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: i am not you \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  4  smallest loss: 1.3556903896858303\n",
            "Time taken for the epoch 689.5097 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 5 Batch: 748 Loss: 1.2956\n",
            "Epoch: 5 Batch: 1496 Loss: 1.9400\n",
            "Epoch: 5 Batch: 2244 Loss: 1.7217\n",
            "Epoch: 5 Batch: 2992 Loss: 1.5920\n",
            "Epoch: 5 Batch: 3740 Loss: 1.4136\n",
            "Epoch: 5 Batch: 4488 Loss: 1.3977\n",
            "Epoch: 5 Batch: 4494 Loss: 1.3301\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not going to be a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not going to be a good time \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not going to be a good time \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: i am not you \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  5  smallest loss: 1.330067037580699\n",
            "Time taken for the epoch 688.2467 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 6 Batch: 748 Loss: 1.2003\n",
            "Epoch: 6 Batch: 1496 Loss: 1.3541\n",
            "Epoch: 6 Batch: 2244 Loss: 1.6812\n",
            "Epoch: 6 Batch: 2992 Loss: 1.6041\n",
            "Epoch: 6 Batch: 3740 Loss: 1.2502\n",
            "Epoch: 6 Batch: 4488 Loss: 1.2148\n",
            "Epoch: 6 Batch: 4493 Loss: 1.3062\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not sure you are not going to be a little while \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not sure you are not going to be a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not sure you are a little rusty \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure you are not going to be a good time \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not going to do \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: i am not sure you are not a little late \n",
            "##################################################\n",
            "Checkpoint Saved!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch so far:  6  smallest loss: 1.3061707140819792\n",
            "Time taken for the epoch 689.8050 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 7 Batch: 748 Loss: 1.2834\n",
            "Epoch: 7 Batch: 1496 Loss: 1.5884\n",
            "Epoch: 7 Batch: 2244 Loss: 1.6224\n",
            "Epoch: 7 Batch: 2992 Loss: 1.3789\n",
            "Epoch: 7 Batch: 3740 Loss: 1.3127\n",
            "Epoch: 7 Batch: 4488 Loss: 1.4602\n",
            "Epoch: 7 Batch: 4494 Loss: 1.2841\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not going to do \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: you are not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  7  smallest loss: 1.2841249026046304\n",
            "Time taken for the epoch 689.5795 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 8 Batch: 748 Loss: 1.1772\n",
            "Epoch: 8 Batch: 1496 Loss: 1.2322\n",
            "Epoch: 8 Batch: 2244 Loss: 1.5556\n",
            "Epoch: 8 Batch: 2992 Loss: 1.5368\n",
            "Epoch: 8 Batch: 3740 Loss: 1.2424\n",
            "Epoch: 8 Batch: 4488 Loss: 1.1077\n",
            "Epoch: 8 Batch: 4493 Loss: 1.2625\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not sure you are not going to be a good time \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not going to do \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not sure you are not sure \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not sure you are not a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: i am not sure it is a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not sure \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not going to do \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: you are not sure \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  8  smallest loss: 1.2625017174629898\n",
            "Time taken for the epoch 689.3660 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 9 Batch: 748 Loss: 1.2973\n",
            "Epoch: 9 Batch: 1496 Loss: 1.5009\n",
            "Epoch: 9 Batch: 2244 Loss: 1.5329\n",
            "Epoch: 9 Batch: 2992 Loss: 1.4836\n",
            "Epoch: 9 Batch: 3740 Loss: 1.2434\n",
            "Epoch: 9 Batch: 4488 Loss: 1.3640\n",
            "Epoch: 9 Batch: 4493 Loss: 1.2424\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not sure you are not going to be a good time \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are not sure \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not sure you are not going to do \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not sure you are not sure \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not sure you are not a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: oh \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not sure \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not sure you are not going to do \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: you are going to be a lot of pressure \n",
            "##################################################\n",
            "Checkpoint Saved!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch so far:  9  smallest loss: 1.2424221837085374\n",
            "Time taken for the epoch 689.4165 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 10 Batch: 748 Loss: 1.1966\n",
            "Epoch: 10 Batch: 1496 Loss: 1.6060\n",
            "Epoch: 10 Batch: 2244 Loss: 1.4737\n",
            "Epoch: 10 Batch: 2992 Loss: 1.5292\n",
            "Epoch: 10 Batch: 3740 Loss: 1.1201\n",
            "Epoch: 10 Batch: 4488 Loss: 1.2672\n",
            "Epoch: 10 Batch: 4494 Loss: 1.2235\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: what \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are not sure \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not sure you are not sure \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not sure it is a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: oh \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure it is a good time \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: you are going to be a lot of rings \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  10  smallest loss: 1.223542156542186\n",
            "Time taken for the epoch 689.7950 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 11 Batch: 748 Loss: 1.0998\n",
            "Epoch: 11 Batch: 1496 Loss: 1.3557\n",
            "Epoch: 11 Batch: 2244 Loss: 1.4919\n",
            "Epoch: 11 Batch: 2992 Loss: 1.4426\n",
            "Epoch: 11 Batch: 3740 Loss: 1.1774\n",
            "Epoch: 11 Batch: 4488 Loss: 1.1240\n",
            "Epoch: 11 Batch: 4493 Loss: 1.2051\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not sure you are not going to be a good time \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not sure you are not a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: oh \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure it is a good time \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not sure you are a witch \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: you are not sure you are a little late \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  11  smallest loss: 1.2050608416699131\n",
            "Time taken for the epoch 690.2863 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 12 Batch: 748 Loss: 1.1551\n",
            "Epoch: 12 Batch: 1496 Loss: 1.5619\n",
            "Epoch: 12 Batch: 2244 Loss: 1.5198\n",
            "Epoch: 12 Batch: 2992 Loss: 1.5343\n",
            "Epoch: 12 Batch: 3740 Loss: 1.1520\n",
            "Epoch: 12 Batch: 4488 Loss: 1.2068\n",
            "Epoch: 12 Batch: 4494 Loss: 1.1876\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not sure you are not going to be a good time \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: i am not sure you are not a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: oh \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure it is a good time \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not sure you are a witch \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: you are not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "##################################################\n",
            "Checkpoint Saved!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch so far:  12  smallest loss: 1.1876367448380454\n",
            "Time taken for the epoch 692.0993 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 13 Batch: 748 Loss: 1.0412\n",
            "Epoch: 13 Batch: 1496 Loss: 1.1334\n",
            "Epoch: 13 Batch: 2244 Loss: 1.5348\n",
            "Epoch: 13 Batch: 2992 Loss: 1.3789\n",
            "Epoch: 13 Batch: 3740 Loss: 1.1246\n",
            "Epoch: 13 Batch: 4488 Loss: 1.0664\n",
            "Epoch: 13 Batch: 4493 Loss: 1.1705\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not sure you are not going to do \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not sure you are a good time \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: oh \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: oh \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure it is a good time \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not sure you are a witch \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: you are not a lot of other to the woods \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  13  smallest loss: 1.1704925509934327\n",
            "Time taken for the epoch 692.2266 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 14 Batch: 748 Loss: 1.2018\n",
            "Epoch: 14 Batch: 1496 Loss: 1.4641\n",
            "Epoch: 14 Batch: 2244 Loss: 1.4494\n",
            "Epoch: 14 Batch: 2992 Loss: 1.2817\n",
            "Epoch: 14 Batch: 3740 Loss: 1.0800\n",
            "Epoch: 14 Batch: 4488 Loss: 1.2194\n",
            "Epoch: 14 Batch: 4494 Loss: 1.1539\n",
            "####################\n",
            "Greedy| Q: Hello ?  A: hello \n",
            "%\n",
            "Greedy| Q: Hey what is up ?  A: i am not \n",
            "%\n",
            "Greedy| Q: How are you doing ?  A: i am not sure you are not sure you are not sure you are not sure you are not sure you are not sure you are \n",
            "%\n",
            "Greedy| Q: Will you be my friend ?  A: i am not sure you are not \n",
            "%\n",
            "Greedy| Q: What are you doing right now ?  A: i am not sure you are a good start \n",
            "%\n",
            "Greedy| Q: What is your favorite restaurant ?  A: oh \n",
            "%\n",
            "Greedy| Q: What is your favorite movie ?  A: oh \n",
            "%\n",
            "Greedy| Q: What is your favorite country ?  A: i am not sure \n",
            "%\n",
            "Greedy| Q: Who are you ?  A: i am not you \n",
            "%\n",
            "Greedy| Q: Do you want to go out with me ?  A: i am not sure you are not \n",
            "%\n",
            "Greedy| Q: What came first eggs or chickens ?  A: you are not sure you are a lot of other peoples business \n",
            "##################################################\n",
            "Checkpoint Saved!\n",
            "Best epoch so far:  14  smallest loss: 1.1539458820889916\n",
            "Time taken for the epoch 691.2006 sec\n",
            "\n",
            "========================================\n",
            "Epoch: 15 Batch: 748 Loss: 1.0298\n",
            "Epoch: 15 Batch: 1496 Loss: 1.0245\n",
            "Epoch: 15 Batch: 2244 Loss: 1.4990\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-9f73c70d6dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8xCfVFpO73cS",
        "outputId": "122432fd-d8d5-4aea-8d58-2054a0493654"
      }
    }
  ]
}